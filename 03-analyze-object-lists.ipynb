{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e775206-3ae8-4610-9140-df1673e8c322",
   "metadata": {},
   "source": [
    "# Use Data from the OSDF to Run Jobs\n",
    "\n",
    "In this section of the tutorial, we will expand our horizons from analyzing one file at a time (accessing the data using the Pelican CLI or PelicanFS) to analyzing many files, running this analysis as a workload on the OSPool, integrated with the OSDF/Pelican. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d1249-ad68-4d6e-b279-ffbc9514dc00",
   "metadata": {},
   "source": [
    "## Starting Data File\n",
    "\n",
    "We will use the station list for this example: \n",
    "\n",
    "```\n",
    "osdf:///aws-opendata/us-east-1/noaa-ghcn-pds/ghcnd-stations.txt\n",
    "```\n",
    "\n",
    "Download it as shown in the [command line client notebook](01-get-and-share-objects.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c0b8e-d524-47d0-9720-f0dee16a6e17",
   "metadata": {},
   "source": [
    "## Scenario: a List of Jobs\n",
    "\n",
    "Suppose we wanted to run our analysis on each station. How many stations are there, again? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a1586-edaf-4f1c-b739-7d25ea131329",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l ghcnd-stations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10338c9-3c62-45fa-8536-e33bf14b9536",
   "metadata": {},
   "source": [
    "That's a long list of tasks to run!\n",
    "\n",
    "Luckily, this workload profile - a list of jobs - is a perfect fit for execution via an HTCondor Access Point, on a system \n",
    "like the Open Science Pool. All we have to do to define this workload is to make a list and a job template. \n",
    "\n",
    "We could use the whole ghcnd-stations.txt file as our list, but for simplicity, we'll cut the full list down to about 10 stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b155d-9b6b-4100-9751-346691e4538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 126040 ghcnd-stations.txt | tail -n 10 | cut -d \" \" -f 1 > station_list.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de949654-ec92-4323-a0d5-bf7d89bedc7b",
   "metadata": {},
   "source": [
    "## Job Template\n",
    "\n",
    "The following information needs to be communicated in the HTCondor job file: \n",
    "\n",
    "- **Software environment** \n",
    "    - The job needs to bring along a software environment with needed dependencies (Python, pandas, matplotlib)\n",
    "    - in our example, we will use an existing container with these tools installed (that also happens to be available via the OSDF)\n",
    "- **What the job should run**\n",
    "    - The command to be executed is listed in the `executable` and `arguments` lines of the submit file. \n",
    "    - For our example, the executable is the `example.py` script and the argument is the station ID. \n",
    "- **Inputs (both scripts and data)**\n",
    "    - All the inputs needed by the executable must also be transferred with the jobs. \n",
    "    - We need to include both the helper script for the code and the Pelican URL to the data file. **HTCondor has its own code that is able to leverage the Pelican client when an input file takes the form of a Pelican URL.**\n",
    "- **Recording information about the job**\n",
    "    - As with many other schedulers, HTCondor provides options for recording the standard output and error \n",
    "    of a running job. Note below that these files are organized into their own directory. \n",
    "- **Resource needs**\n",
    "    - Default resources that should be set for every HTCondor job list include cores, memory (RAM) and local disk on the execution point. \n",
    "    - For this example, we will request 1 core, 4GB of RAM and 4GB of disk. \n",
    "\n",
    "Each of these items is reflected in the example submit file. Every line of the submit file (except the last one) \n",
    "should be thought of as the template for one job. At any point \n",
    "in this template where there is data that will be different for each job, we've placed a variable as a placeholder -- \n",
    "the variable format is `$(variable_name)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28690d4a-bafb-4626-be4d-39ead9d35700",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat example.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989530b7-28dd-450c-8b18-7e4e837043f1",
   "metadata": {},
   "source": [
    "The last line (`queue station_id from station_list.txt`) is what transforms this example into a job list -- HTCondor \n",
    "will iterate through the items in our list and create a job for each one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b624eb7-352f-49e3-9120-130fe4b6bcbb",
   "metadata": {},
   "source": [
    "## Submitting Jobs\n",
    "\n",
    "We can now submit our list of jobs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8adc6c-f9fb-49d8-8ed7-993187bcb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "condor_submit example.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa2f600-7f33-46e7-9ef1-0d42569838b1",
   "metadata": {},
   "source": [
    "Jobs can be monitored using `condor_q`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb50cb0-8f6a-422b-afa0-5909bafd17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "condor_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8668cc-04ff-4448-9c08-2d5b6223c763",
   "metadata": {},
   "source": [
    "Once completed, our images will appear in the `results` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c3802-d015-4208-a369-7ad939247853",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
